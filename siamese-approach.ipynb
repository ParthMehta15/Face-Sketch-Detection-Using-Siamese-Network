{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation, Add, Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.regularizers import l1, l2,l1_l2\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE DATA HAS BEEN COVERTED TO NUMPY ARRAY AND SAVED AT THE FOLLOWING LOCATION\n",
    "DATA_LOAD_PATH = './data'\n",
    "MODEL_SAVE_PATH = 'model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class Siamese():\n",
    "\n",
    "    \n",
    "    def __init__(self, categories, categories_test, MODEL_SAVE_PATH):\n",
    "        \n",
    "        \n",
    "        self.dataset = categories\n",
    "        self.test = categories_test\n",
    "        self.MODEL_SAVE_PATH = MODEL_SAVE_PATH\n",
    "        \n",
    "        \n",
    "        def get_siamese_model(self):\n",
    "            \n",
    "            \n",
    "            \n",
    "            def W_init(shape,dtype=None):\n",
    "                \n",
    "                \"\"\"Initialize weights\"\"\"\n",
    "                \n",
    "                values = np.random.normal(loc=0,scale=1e-2,size=shape)\n",
    "                return K.variable(values,dtype=dtype)\n",
    "            \n",
    "            def b_init(shape,dtype=None):\n",
    "                \n",
    "                \"\"\"Initialize bias\"\"\"\n",
    "                \n",
    "                values = np.random.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "                return K.variable(values,dtype=dtype)\n",
    "                    \n",
    "            \n",
    "            \"\"\"\n",
    "                Model architecture\n",
    "            \"\"\"\n",
    "            \n",
    "            input_shape = (256, 256, 3)\n",
    "            \n",
    "            vgg16 = VGG16(weights = \"imagenet\", include_top=False, input_shape = (256, 256, 3))\n",
    "\n",
    "            for layer in vgg16.layers:\n",
    "                print(layer.name)\n",
    "                layer.trainable = False\n",
    "\n",
    "            pre = Model(inputs = vgg16.input, outputs= vgg16.output)\n",
    "            \n",
    "            # Define the tensors for the two input images\n",
    "            left_input = Input(input_shape)\n",
    "            right_input = Input(input_shape)\n",
    "            \n",
    "            # Convolutional Neural Network\n",
    "            model = Sequential()\n",
    "        \n",
    "            model.add(pre)     \n",
    "            \n",
    "            model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_initializer=W_init, bias_initializer=b_init)) #kernel_regularizer=l1(0.001)))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(MaxPooling2D())\n",
    "            model.add(BatchNormalization())\n",
    "            \n",
    "            model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_initializer=W_init, bias_initializer=b_init))#kernel_regularizer=l1(0.001)))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(MaxPooling2D())\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Flatten())\n",
    "            #model.add(Dropout(0.2))\n",
    "            \n",
    "            model.add(Dense(4096, activation='sigmoid', kernel_initializer=W_init, bias_initializer=b_init\n",
    "                           #kernel_regularizer=l1(0.001),\n",
    "                           ))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(BatchNormalization())\n",
    "            \n",
    "            \n",
    "            # Generate the encodings (feature vectors) for the two images\n",
    "            encoded_l = model(left_input)\n",
    "            encoded_r = model(right_input)\n",
    "            \n",
    "            # Add a customized layer to compute the absolute difference between the encodings\n",
    "            L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "            L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "            \n",
    "            # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "            prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "            \n",
    "            # Connect the inputs with the outputs\n",
    "            siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "            \n",
    "           \n",
    "            optimizer = Adam(0.00006)\n",
    "\n",
    "            siamese_net.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            # return the model\n",
    "            return siamese_net\n",
    "            \n",
    "        self.siamese_net = get_siamese_model(self)\n",
    "        \n",
    "        print(self.siamese_net.summary())\n",
    "        \n",
    "        print('Siamese Net Intialised and Loaded')\n",
    "        \n",
    "\n",
    "\n",
    "    def get_train_set(self):\n",
    "\n",
    "            x_anchor=[]\n",
    "            x_examples = []\n",
    "            y=[]\n",
    "\n",
    "\n",
    "            for i in range(len(self.dataset)):\n",
    "                current_class = self.dataset[i]\n",
    "                for j in range(len(current_class)):\n",
    "                    y.append(current_class[j][2])\n",
    "                    x_anchor.append(current_class[j][0])\n",
    "                    x_examples.append(current_class[j][1])\n",
    "\n",
    "            x_anchor = np.asarray(x_anchor)\n",
    "            x_examples = np.asarray(x_examples)\n",
    "            y_batch = np.asarray(y)\n",
    "\n",
    "\n",
    "            print(x_anchor.shape)\n",
    "            print(x_examples.shape)\n",
    "            print(y_batch.shape)\n",
    "\n",
    "            return x_anchor, x_examples, y_batch\n",
    "\n",
    "\n",
    "    def get_test_set(self):\n",
    "\n",
    "            x_anchor=[]\n",
    "            x_examples = []\n",
    "            y=[]\n",
    "\n",
    "            for i in range(len(self.test)):\n",
    "                current_class = self.test[i]\n",
    "                for j in range(len(current_class)):\n",
    "                    y.append(current_class[j][2])\n",
    "                    x_anchor.append(current_class[j][0])\n",
    "                    x_examples.append(current_class[j][1])\n",
    "\n",
    "            x_anchor = np.asarray(x_anchor)\n",
    "            x_examples = np.asarray(x_examples)\n",
    "            y_batch = np.asarray(y)\n",
    "\n",
    "            print(x_anchor.shape)\n",
    "            print(x_examples.shape)\n",
    "            print(y_batch.shape)\n",
    "\n",
    "            return x_anchor, x_examples, y_batch\n",
    "\n",
    "\n",
    "\n",
    "    def get_accuracy(self, preds, y_batch_test):\n",
    "\n",
    "            preds = np.around(preds)\n",
    "            results = metrics.accuracy_score(y_batch_test, preds)\n",
    "\n",
    "            return results\n",
    "        \n",
    "\n",
    "            \n",
    "                      \n",
    "    def train(self):\n",
    "\n",
    "            x_anchor, x_examples, y_batch = self.get_train_set()\n",
    "\n",
    "            x_anchor_test, x_examples_test, y_batch_test = self.get_test_set()\n",
    "\n",
    "            checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "            history = self.siamese_net.fit(x = [x_anchor, x_examples], y=y_batch, epochs=512, batch_size= 32,  verbose = 2, validation_split=0.2, callbacks=[checkpoint])\n",
    "\n",
    "            # summarize history for accuracy\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title('Model Accuracy')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.legend(['Train Accuracy', 'Validation Accuracy'], loc='upper left')\n",
    "            plt.savefig('/kaggle/working/accs.png')\n",
    "            plt.show()\n",
    "\n",
    "            # summarize history for loss\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('Model Loss')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.legend(['Train Loss', 'Validation Loss'], loc='upper left')\n",
    "            plt.savefig('/kaggle/working/losses.png')\n",
    "            plt.show()\n",
    "\n",
    "            y_pred = self.siamese_net.predict([x_anchor_test, x_examples_test])\n",
    "            \n",
    "            accuracy = self.get_accuracy(np.around(y_pred), y_batch_test)\n",
    "            print('Accuracy on Test Set is:')\n",
    "            print(accuracy)\n",
    "\n",
    "            con_mat = confusion_matrix(y_batch_test, np.around(y_pred))\n",
    "\n",
    "            df_cm = pd.DataFrame(con_mat, range(len(con_mat)), range(len(con_mat)))\n",
    "\n",
    "            plt.figure(figsize = (10,7))\n",
    "            sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "            plt.savefig('./conf_matrix.png')\n",
    "\n",
    "\n",
    "            return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "#THE DATA HAS BEEN COVERTED TO NUMPY ARRAY\n",
    "train = np.load(os.path.join(DATA_LOAD_PATH, 'train_colour.npy'),  allow_pickle = True)\n",
    "test = np.load(os.path.join(DATA_LOAD_PATH, 'test_colour.npy'),  allow_pickle = True)\n",
    "\n",
    "# Create Model \n",
    "siamese = Siamese(train, test, MODEL_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save metrics \n",
    "hist = siamese.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(img_path):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    img = cv2.resize(img, (256,256))\n",
    "    norm_image = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    norm_image = np.reshape(norm_image, (1,256,256,3))\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "model=load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
